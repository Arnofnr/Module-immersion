# Module-immersion
Retrouvez ici les contenus à étudier en autonomie du module *immersion*.
_____
**Planning de travail** :

- Du 6 décembre 2019 au 8 janvier 2020 : faire le paragraphe 1.
- Séance en présentiel le 9 janvier 2020.
- Du 10 janvier au 30 janvier 2020 : faire le paragraphe 2.
- Séance en présentiel le  30 janvier 2020.
- Du 31 janvier au 13 février 2020: faire le paragraphe 3.
- Séance en présentiel le 13 février 2020.
______


## 1  Neural Networks, Decision trees, Boosting, Bagging, Random Forests.
*A faire sur la période du 06/12/2019 au 08/01/2020*


### 1.1 Documents de base à consulter en autonomie
- Consulter les chapitres 6 et 8 à 11  dans: (https://github.com/erachelson/Mlclass).
- Régression Lasso: CoursRegLasso.pdf(https://github.com/Certificat-sciences-des-donnees-bigdata/Module-immersion/blob/master/Documents/CoursRegLasso.pdf).
- [Arbres binaires de décision](http://wikistat.fr/pdf/st-m-app-cart.pdf)
- [Agrégation de modèles](http://wikistat.fr/pdf/st-m-app-agreg.pdf) 
- [Réseaux de neurones](http://wikistat.fr/pdf/st-m-app-rn.pdf) 
- [Machines à vecteurs supports](http://wikistat.fr/pdf/st-m-app-svm.pdf) 
- Apprentissage supervisé: slides apprentissageSupervise.pdf dans Documents.


### 1.2 Travail personnel demandé 
Exécuter le notebooks contenus dans les chapitres 6 et 8 à 11 dans: https://github.com/erachelson/Mlclass. 

### 1.3 TP spam
Le TP est disponible ici: https://github.com/wikistat/Apprentissage/tree/master/Spam

## 2 Techniques de virtualisation et containerisation, les plateformes cloud

Cours et séance de TP le 30 janvier.

## 3 Algorithmes stochastiques plus sophistiqués : optimisation parcimonieuse, factorisation non négative de matrice

Slides pour le cours du 13 Fevrier: opti.pdf dans Documents

Notebook pour le TP du 13 Fevrier: tp_7fevrier.ipynb dans Documents
